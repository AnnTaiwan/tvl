import os
from tvl_enc import tacvis
from util.eval_util import load_model, EVAL_PROMPT, get_evaluator
import llama

# è¨­å®šè·¯å¾‘
model_path = r"D:\NSYSU_Fourth_grade\ADV_ML_Final_Project\checkpoints\tvl_llama_vittiny.pth"
llama_dir = r"D:\NSYSU_Fourth_grade\ADV_ML_Final_Project\Prompt-Highlighter\base_models\LLaVA_checkpoints\llava-v1.5-7b"

# è¼‰å…¥æ¨¡å‹
model_args = type('', (), {})()  # ç©ºçš„ namespace object
model_args.llama_type = "llama-2-7b"
model_args.has_lora = True
model_args.active_modality_names = ["tactile", "vision"]
model_args.tactile_model = "vit_tiny_patch16_224"
model_args.lora_rank = 4
model_args.lora_layer_idxs = None
model_args.checkpoint_path = None
model_args.lora_modality_names = []

model = load_model(model_path, llama_dir, model_args)
model.eval()

# ä½¿ç”¨è€…è¼¸å…¥åœ–ç‰‡è·¯å¾‘
IMAGE_NAME = '93-0.0398557186126709'
TACTILE_IMAGE_PATH = "tactile/"+IMAGE_NAME+".jpg"
IMAGE_PATH = "image/"+IMAGE_NAME+".jpg"

# vision_path = input("è«‹è¼¸å…¥ vision image æª”æ¡ˆè·¯å¾‘ï¼š")
vision_path = IMAGE_NAME
while not os.path.exists(vision_path):
    vision_path = input("æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œè«‹å†è¼¸å…¥ vision image è·¯å¾‘ï¼š")

tactile_path = TACTILE_IMAGE_PATH
# tactile_path = input("è«‹è¼¸å…¥ tactile image æª”æ¡ˆè·¯å¾‘ï¼š")
while not os.path.exists(tactile_path):
    tactile_path = input("æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œè«‹å†è¼¸å…¥ tactile image è·¯å¾‘ï¼š")

# è¼‰å…¥è³‡æ–™
vision_data = tacvis.load_vision_data(vision_path, device="cuda").unsqueeze(0)
tactile_data = tacvis.load_tactile_data(tactile_path, device="cuda").unsqueeze(0)

# çµ„æˆ inputs
inputs = {
    "vision": [vision_data, 1],
    "tactile": [tactile_data, 1]
}

# è¨­å®š prompt
prompt = "This image gives tactile feelings of?"

# ç”¢ç”Ÿçµæœ
results = model.generate(
    inputs,
    [llama.format_prompt(prompt)],
    max_gen_len=256
)

# è¼¸å‡º
assistant_response = results[0].strip()
print(f"\n\nğŸ–¥ï¸ æ¨¡å‹é æ¸¬ï¼š{assistant_response}")

# ç”¨å…§å»º evaluator æ‰“åˆ†æ•¸
evaluator = get_evaluator("gpt-4", EVAL_PROMPT)
gt_label = input("è«‹è¼¸å…¥ ground truth label (for evaluation)ï¼š")
score = evaluator(prompt=prompt, assistant_response=assistant_response, correct_response=gt_label)
print(f"ğŸ’¯ è©•åˆ†çµæœï¼š{score}")
